name: Databricks artifacts publisher
on:
  workflow_dispatch:
env:
  ARTIFACT_BUCKET: immuta-platform-artiacts
  IMMUTA_RELEASE: 2024.2.0
  RELEASE_DATE: 20240430
permissions:
  id-token: write
  contents: read
jobs:
  publish:
    runs-on: ubuntu-latest
    steps:
    - name: Checkout Repo
      uses: actions/checkout@v4
    - name: Configure AWS Creds
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-region: us-east-1
        role-to-assume: arn:aws:iam::931788537711:role/github-actions
    - name: Download files from s3
      run: |
        for file in allowedCallingClasses.json get_unity_token.py immuta-benchmark-suite.dbc immuta-spark-hive-${{env.IMMUTA_RELEASE}}_${{env.RELEASE_DATE}}-spark-3.3.0-public.jar immuta-validation.py immuta_cluster_init_script.sh immuta_cluster_init_script_proxy.sh obscuredCommands.yaml; do
          aws s3 cp s3://immuta-platform-artifacts/hadoop/databricks/${{env.IMMUTA_RELEASE}}/11.x/$file .
        done
